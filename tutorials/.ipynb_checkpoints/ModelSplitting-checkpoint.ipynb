{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e180ad92-2158-4b0d-9635-7b439e4a225e",
   "metadata": {},
   "source": [
    "# Model Splitting: Creating Nested Models While Maintaining Functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d7f09-6dae-48f1-9738-7cf204079c12",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate how to split an existing Keras model into a sequence of nested models. The goal is to preserve the same underlying function of the original model but restructure it into smaller, modular components for easier inspection or experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c11b5b-7282-4126-a615-816ea532174b",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up the Environment\n",
    "\n",
    "If you're running this tutorial on **Google Colab**, follow these steps to install the required libraries and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f40c96-c94a-4886-93d0-64f0a339e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab: install the library\n",
    "on_colab = \"google.colab\" in str(get_ipython())\n",
    "if on_colab:\n",
    "    import sys  # noqa: avoid having this import removed by pycln\n",
    "\n",
    "    # install dev version for dev doc, or release version for release doc\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install git+https://github.com/ducoffeM/keras_custom@main#egg=decomon\n",
    "    # install desired backend (by default torch)\n",
    "    !{sys.executable} -m pip install \"torch\"\n",
    "    !{sys.executable} -m pip install \"keras\"\n",
    "\n",
    "    # extra librabry used in this notebook\n",
    "    !{sys.executable} -m pip install \"numpy\"\n",
    "    # missing imports IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97564f9-a24e-4bd9-bf3f-a0643c4cb172",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries\n",
    "Next, we import the necessary libraries for our model and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f0d82-f2a3-49d0-9b0f-b7975655f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3c8c8-b504-4a7f-8894-1fad81964a8d",
   "metadata": {},
   "source": [
    "## Step 3: Download and Preprocess the Image\n",
    "We will use an image of an elephant for our prediction. If the image file is not present, it will be downloaded from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0c3df-e9ed-4115-b350-437b34662399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the image is already available\n",
    "if not os.path.isfile('elephant.jpg'):\n",
    "    !wget https://upload.wikimedia.org/wikipedia/commons/f/f9/Zoorashia_elephant.jpg -O elephant.jpg\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'elephant.jpg'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)  # Add batch dimension\n",
    "x = preprocess_input(x)  # Preprocess image for ResNet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c01d9-cc65-4f70-b8b7-fa1b186c64ef",
   "metadata": {},
   "source": [
    "## Step 4: Load the Pre-trained Model\n",
    "We will use the ResNet50 model pre-trained on ImageNet to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20184c-7888-4558-846a-ce10363a5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet50 model without the final classification layer\n",
    "model = ResNet50(weights='imagenet', classifier_activation=None)\n",
    "\n",
    "# Make a prediction\n",
    "preds = model.predict(x)\n",
    "\n",
    "# Decode the predictions to show the top 3 predictions\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1292a6e-9c17-40ab-9301-18d2bb677ee4",
   "metadata": {},
   "source": [
    "## Step 5: Split the Model into Nested Models\n",
    "The goal is to break down the ResNet50 model into smaller, modular nested models. Each nested model will correspond to a part of the original model up to a specific layer. The split will be based on the activations of certain layers.\n",
    "\n",
    "**Identify Layers to Split**\n",
    "We will first identify the layers with activation functions (ReLU layers) and choose some layers to use as split points. For simplicity, let's pick layers at indices [0, 4, 8, 12, -1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b7726-8634-4373-9c6e-721f6fafe7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_custom\n",
    "from keras_custom.model import get_nested_model\n",
    "\n",
    "# Identify activation layers (ReLU) in the model\n",
    "relu_name = [e.name for e in model.layers if isinstance(e, Activation) and e.name.split('_')[-1] == 'out']\n",
    "\n",
    "# Select layers to split at\n",
    "indices = [0, 4, 8, 12, -1]\n",
    "split = [relu_name[i] for i in indices] + [model.layers[-1].name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffcda6a-df0b-4e90-8be4-156ea49a2fcc",
   "metadata": {},
   "source": [
    "**Create Nested Models**\n",
    "\n",
    "Now, we will create a list of nested models by using the selected layers for the splits. Each nested model is built starting from the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92b9b5-4578-4eab-8fd9-7478fa9d51a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f7d53b-b6a6-4db5-9f83-cd7ba185a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('elephant.jpg'):\n",
    "    !wget https://upload.wikimedia.org/wikipedia/commons/f/f9/Zoorashia_elephant.jpg -O elephant.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4751ab-b93d-4d86-acea-f56adc2adbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "Predicted: [('n02504013', 'Indian_elephant', 16.045454), ('n02504458', 'African_elephant', 14.072982), ('n01871265', 'tusker', 13.382182)]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet', classifier_activation=None)\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dd9c977-f1a1-4502-b644-003b9af14727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_custom\n",
    "from keras_custom.model import get_nested_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "011e68d6-d4b8-4e45-a410-076cf23e7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_name = [e.name for e in model.layers if isinstance(e, Activation) and e.name.split('_')[-1]=='out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba3b2a40-da54-4562-9b52-3f50c94afaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[0, 4, 8, 12, -1]\n",
    "split = [relu_name[i] for i in indices]+[model.layers[-1].name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da8c53bc-d86a-47b7-884a-ec12b5b6746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 3, 224, 224), dtype=float32, sparse=False, name=keras_tensor_745>\n",
      "<KerasTensor shape=(None, 256, 56, 56), dtype=float32, sparse=False, name=keras_tensor_770>\n",
      "<KerasTensor shape=(None, 512, 28, 28), dtype=float32, sparse=False, name=keras_tensor_925>\n",
      "<KerasTensor shape=(None, 1024, 14, 14), dtype=float32, sparse=False, name=keras_tensor_1080>\n",
      "<KerasTensor shape=(None, 1024, 14, 14), dtype=float32, sparse=False, name=keras_tensor_1231>\n",
      "<KerasTensor shape=(None, 2048, 7, 7), dtype=float32, sparse=False, name=keras_tensor_1310>\n"
     ]
    }
   ],
   "source": [
    "layer_in = None\n",
    "input_shape_wo_batch = list(model.input.shape[1:])\n",
    "nested_models=[]\n",
    "for name in split:\n",
    "    layer_out = model.get_layer(name)\n",
    "    nested_model = get_nested_model(model, layer_out, layer_in, input_shape_wo_batch)\n",
    "    layer_in=layer_out\n",
    "    nested_models.append(nested_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb3ba2b-6d1c-4fb1-8d8a-0b267cc43f91",
   "metadata": {},
   "source": [
    "we can create the same models but as a sequential of nested models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaf73b6d-04b1-462b-80cf-ec5dd93f2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = Sequential(layers=nested_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f64e8d-643f-4936-b8e8-a1328fa75139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_ = model_seq.predict(x)\n",
    "\n",
    "np.testing.assert_almost_equal(preds, preds_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d0641-a4cc-4f8e-adfc-1778a41434fe",
   "metadata": {},
   "source": [
    "We obtain the same prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdc2d21e-666e-4c89-9486-a1e383d1abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504013', 'Indian_elephant', 16.045454), ('n02504458', 'African_elephant', 14.072982), ('n01871265', 'tusker', 13.382182)]\n"
     ]
    }
   ],
   "source": [
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28cdaab7-9582-44af-9d0f-a99d1d2a2576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"./ResNet50.png\" width=\"800\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dot_img_file_backward = './ResNet50.png'\n",
    "keras.utils.plot_model(model_seq, to_file=dot_img_file_backward, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "display(HTML('<div style=\"text-align: center;\"><img src=\"{}\" width=\"800\"/></div>'.format(dot_img_file_backward)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec02e06-a179-4ea6-b235-5d26072834ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
